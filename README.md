# BioRes MAIA

**Sistema BIORES: Generaci√≥n Autom√°tica de Res√∫menes en Lenguaje Simple para Documentos Biom√©dicos usando SLMs**

Pipeline completo de preprocesamiento, entrenamiento y validaci√≥n para la clasificaci√≥n y simplificaci√≥n autom√°tica de textos m√©dicos. El sistema permite transformar documentos biom√©dicos complejos (NO_PLS) a lenguaje simple y accesible (PLS - Plain Language Summary), facilitando la comprensi√≥n de informaci√≥n m√©dica para el p√∫blico general.

## üë• Integrantes

**Maestr√≠a en Inteligencia Artificial**  
Universidad de los Andes, Bogot√° D.C.

- **Daniel S. Moreno-Sandoval** - [ds.morenos1@uniandes.edu.co](mailto:ds.morenos1@uniandes.edu.co)
- **William A. Moreno-Agudelo** - [w.morenoa@uniandes.edu.co](mailto:w.morenoa@uniandes.edu.co)
- **Gustavo Contreras-Herrera** - [g.contreras118@uniandes.edu.co](mailto:g.contreras118@uniandes.edu.co)
- **Yernel A. Cardona-Chao** - [ma.cardona@uniandes.edu.co](mailto:ma.cardona@uniandes.edu.co)

## üéØ Objetivo del Proyecto

El proyecto BioRes MAIA aborda el problema de la brecha de alfabetizaci√≥n en salud mediante el desarrollo de un sistema automatizado que:

1. **Clasifica** documentos biom√©dicos seg√∫n su nivel de complejidad (PLS vs NO_PLS)
2. **Simplifica** textos m√©dicos complejos a lenguaje llano y accesible
3. **Eval√∫a** la calidad y legibilidad de las simplificaciones generadas
4. **Despliega** una interfaz web interactiva para uso pr√°ctico

El sistema utiliza Small Language Models (SLMs) fine-tuneados con t√©cnicas de Parameter-Efficient Fine-Tuning (PEFT) como LoRA, optimizando el balance entre rendimiento y recursos computacionales.

## üìã Requisitos

- Python 3.10+
- Docker & Docker Compose (para despliegue con contenedores)
- UV (opcional, para instalaci√≥n r√°pida de dependencias)

### Dependencias principales

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![spaCy](https://img.shields.io/badge/spaCy-09A3D5?style=for-the-badge&logo=spacy&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)
![Pydantic](https://img.shields.io/badge/Pydantic-E92063?style=for-the-badge&logo=pydantic&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Hugging Face](https://img.shields.io/badge/ü§ó_Hugging_Face-FFD21E?style=for-the-badge)

El proyecto utiliza las siguientes dependencias clave organizadas por categor√≠a:

#### Procesamiento de texto y NLP
- **spacy** (‚â•3.5.0): Procesamiento de lenguaje natural y tokenizaci√≥n
- **beautifulsoup4** (‚â•4.12.0): Parsing y limpieza de HTML
- **unidecode** (‚â•1.3.6): Normalizaci√≥n de caracteres Unicode
- **ftfy** (‚â•6.1.1): Correcci√≥n autom√°tica de texto corrupto
- **regex** (‚â•2023.8.8): Expresiones regulares avanzadas
- **textstat** (‚â•0.7.11): M√©tricas de legibilidad de texto

#### Machine Learning y Deep Learning
- **scikit-learn** (‚â•1.5.0): Algoritmos de clasificaci√≥n y m√©tricas
- **peft** (‚â•0.18.0): Parameter-Efficient Fine-Tuning para LLMs
- **stable-baselines3** (==2.3.0): Algoritmos de reinforcement learning
- **gymnasium** (==0.29.1): API est√°ndar para entornos de RL

#### Manipulaci√≥n de datos
- **pandas** (‚â•1.5.0): An√°lisis y manipulaci√≥n de datos tabulares
- **pyarrow** (‚â•11.0.0): Formato columnar eficiente para datasets grandes

#### Visualizaci√≥n
- **matplotlib** (‚â•3.10.7): Gr√°ficos y visualizaciones est√°ticas
- **plotly** (‚â•5.24.0): Visualizaciones interactivas
- **altair** (‚â•5.3.0): Gram√°tica declarativa de visualizaci√≥n
- **streamlit** (‚â•1.39.0): Framework para aplicaciones web de ML/AI

#### API y servicios web
- **fastapi** (‚â•0.104.0): Framework web as√≠ncrono de alto rendimiento
- **uvicorn[standard]** (‚â•0.24.0): Servidor ASGI para FastAPI
- **pydantic** (‚â•2.5.0): Validaci√≥n de datos con type hints
- **python-multipart** (‚â•0.0.6): Parsing de formularios multipart

#### Almacenamiento y I/O
- **fsspec** (‚â•2023.11.0): Sistema de archivos unificado (S3, local, etc.)
- **smart-open** (‚â•6.3.0): Lectura/escritura transparente en S3, HTTP, etc.
- **pyyaml** (‚â•6.0.3): Parsing de archivos de configuraci√≥n YAML

#### Utilidades
- **tqdm** (‚â•4.65.0): Barras de progreso para iteraciones
- **joblib** (‚â•1.5.2): Paralelizaci√≥n y caching de funciones
- **tqdm-joblib** (‚â•0.0.5): Integraci√≥n de tqdm con joblib
- **watchdog** (‚â•6.0.0): Monitoreo de cambios en archivos
- **filelock** (‚â•3.20.0): Bloqueo de archivos multiplataforma
- **lxml** (‚â•6.0.2): Parsing r√°pido de XML/HTML

## üöÄ Instalaci√≥n

### Opci√≥n 1: Instalaci√≥n local con UV (recomendado)

```bash
# Instalar UV si no lo tienes
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clonar el repositorio
git clone https://github.com/06danielsms/biores_maia.git
cd biores_maia

# Instalar el proyecto y todas sus dependencias
uv pip install -e .
```

### Opci√≥n 2: Instalaci√≥n local con pip

```bash
# Clonar el repositorio
git clone https://github.com/06danielsms/biores_maia.git
cd biores_maia

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar el proyecto
pip install -e .
```

## üê≥ Despliegue con Docker

### Construcci√≥n y ejecuci√≥n

```bash
# Construir y levantar el servicio Streamlit
docker-compose up --build

# O en modo detached (segundo plano)
docker-compose up -d --build
```

### Acceso a la aplicaci√≥n

**Despliegue local:**
Una vez levantado, abre tu navegador en: **http://localhost:8501**

**Despliegue en producci√≥n (AWS):**
La aplicaci√≥n est√° desplegada en AWS EC2 y disponible en: **http://ec2-54-163-93-65.compute-1.amazonaws.com/**

#### Caracter√≠sticas de la instancia EC2

- **Tipo de instancia**: t2.large
- **vCPUs**: 2
- **Memoria RAM**: 8 GiB
- **Regi√≥n**: us-east-1 (N. Virginia)
- **Sistema operativo**: Amazon Linux 2 / Ubuntu Server
- **Almacenamiento**: EBS optimizado
- **Red**: VPC con configuraci√≥n de seguridad para tr√°fico HTTP (puerto 80)

### Comandos √∫tiles

```bash
# Ver logs en tiempo real
docker-compose logs -f

# Detener el servicio
docker-compose down

# Reconstruir la imagen (despu√©s de cambiar dependencias)
docker-compose up --build --force-recreate

# Ver estado del contenedor
docker-compose ps
```

## üìä Ejemplos de uso

### Aplicaci√≥n Web Interactiva

La aplicaci√≥n Streamlit de BioRes MAIA proporciona una interfaz visual completa para trabajar con el pipeline de simplificaci√≥n de textos m√©dicos. Incluye dos m√≥dulos principales:

#### 1. M√≥dulo de Preprocesamiento y Configuraci√≥n

Este m√≥dulo permite limpiar y preparar textos m√©dicos antes del an√°lisis o entrenamiento.
![alt text](assets/preprocess.png)
**Caracter√≠sticas principales:**

- **Limpieza de texto configurable:**
  - Eliminaci√≥n de HTML y etiquetas
  - Normalizaci√≥n de Unicode y espacios en blanco
  - Reemplazo de URLs y correos electr√≥nicos
  - De-identificaci√≥n de PHI (Protected Health Information)
  - Normalizaci√≥n de n√∫meros (keep/normalize/mask)
  - Control de puntuaci√≥n y may√∫sculas/min√∫sculas

- **Chunking inteligente:**
  - Configuraci√≥n de tokens por chunk (50-400 tokens)
  - Control de overlap entre chunks (0-120 tokens)
  - Vista previa de chunks generados

- **An√°lisis de m√©tricas:**
  - Visualizaci√≥n de diferencias entre texto original y procesado
  - M√©tricas de reducci√≥n de tokens y longitud
  - Estad√≠sticas de vocabulario y longitud promedio de palabras
  - Histogramas, boxplots y correlaciones entre m√©tricas
  - Comparaci√≥n autom√°tica entre documentos PLS y NO_PLS

**Ejemplo de uso:**

```python
# Acceder al m√≥dulo de Preprocesamiento
1. Navega a la pesta√±a "Preprocesamiento" en la barra lateral
2. Ingresa o carga un texto m√©dico en el √°rea de texto
3. Configura las opciones de limpieza:
   - Activa "Eliminar HTML" para limpiar etiquetas
   - Activa "De-identificar PHI" para anonimizar informaci√≥n sensible
   - Selecciona "normalize" para normalizar n√∫meros
   - Ajusta "Tokens por chunk" a 120 y "Overlap" a 20
4. Haz clic en "Aplicar preprocesamiento"
5. Revisa el texto procesado y las m√©tricas de reducci√≥n
6. Descarga el resultado o visualiza los chunks generados
```

**An√°lisis de m√©tricas de preprocesamiento:**

El m√≥dulo incluye herramientas avanzadas para analizar las caracter√≠sticas textuales:

- **M√©tricas de legibilidad:** Flesch Reading Ease, ARI, Coleman-Liau
- **Diversidad l√©xica:** Type-Token Ratio (TTR), Hapax Legomena
- **Estad√≠sticas estructurales:** Longitud de palabras/oraciones, densidad de stopwords
- **Visualizaciones interactivas:** Histogramas de densidad, boxplots comparativos, matrices de correlaci√≥n

#### 2. M√≥dulo de Validaci√≥n e Inferencia

Este m√≥dulo permite validar modelos y generar simplificaciones en tiempo real usando modelos fine-tuneados.
![alt text](assets/inference.png)

**Caracter√≠sticas principales:**

- **Clasificaci√≥n autom√°tica de textos:**
  - Usa un clasificador BERT fine-tuneado para determinar si un texto es PLS o NO_PLS
  - Evita procesamiento innecesario de textos que ya est√°n simplificados
  - Proporciona feedback sobre el nivel de complejidad del texto

- **Inferencia con m√∫ltiples configuraciones:**
  - **Modelo base:** Qwen 2.5 3B Instruct sin fine-tuning
  - **LoRA (Fine-tuned):** Adaptadores LoRA entrenados espec√≠ficamente para simplificaci√≥n m√©dica
  - **TD3 (Optimizaci√≥n din√°mica):** Agente de reinforcement learning que ajusta autom√°ticamente temperatura y top_p

- **Par√°metros de generaci√≥n configurables:**
  - **Temperature** (0.1-1.0): Controla la creatividad vs determinismo
  - **Top-p** (0.1-1.0): Nucleus sampling para diversidad controlada
  - **Max tokens** (64-512): Longitud m√°xima del resumen generado

- **Evaluaci√≥n de legibilidad:**
  - C√°lculo autom√°tico del Flesch Reading Ease Score
  - Interpretaci√≥n del nivel de dificultad (muy f√°cil a muy dif√≠cil)
  - Comparaci√≥n lado a lado del texto original vs simplificado

**Ejemplo de uso:**

```python
# Acceder al m√≥dulo de Validaci√≥n
1. Navega a la pesta√±a "Validaci√≥n" en la barra lateral
2. Selecciona la configuraci√≥n del modelo:
   - Activa "Usar LoRA (Fine-tuned)" para mejor calidad
   - Opcionalmente activa "Usar TD3" para optimizaci√≥n autom√°tica
3. Si no usas TD3, configura manualmente:
   - Temperature: 0.7 (balance creatividad/precisi√≥n)
   - Top-p: 0.9 (diversidad del vocabulario)
   - Max tokens: 256 (longitud del resumen)
4. Ingresa el texto m√©dico complejo en el √°rea de entrada
5. Haz clic en "üöÄ Generar Resumen Simplificado"
6. Espera mientras:
   - El clasificador BERT determina si el texto es PLS o NO_PLS
   - Si es NO_PLS, el modelo genera la simplificaci√≥n
   - Si es PLS, se omite la generaci√≥n (ya est√° simplificado)
7. Revisa el resultado:
   - Compara texto original vs simplificado
   - Analiza el Flesch Reading Ease Score
   - Revisa los tiempos de clasificaci√≥n y generaci√≥n
8. Descarga el resumen simplificado si lo necesitas
```

**Consideraciones de rendimiento:**

‚ö†Ô∏è La aplicaci√≥n se ejecuta en una instancia EC2 t2.large con recursos limitados:
- **Primera ejecuci√≥n:** Puede tardar varios minutos al descargar modelos
- **Clasificaci√≥n:** ~10-30 segundos con BERT
- **Generaci√≥n:** ~1-5 minutos dependiendo del texto y configuraci√≥n
- **Memoria:** El modelo puede liberarse manualmente con el bot√≥n "üóëÔ∏è Liberar Memoria"

**Interpretaci√≥n de resultados:**

El Flesch Reading Ease Score indica:
- **> 80:** Muy f√°cil de leer (nivel primaria)
- **60-80:** Est√°ndar - F√°cil (nivel secundaria)
- **50-60:** Moderadamente dif√≠cil (nivel universitario)
- **30-50:** Dif√≠cil (nivel acad√©mico)
- **< 30:** Muy dif√≠cil (nivel especializado)

Los res√∫menes generados por BioRes MAIA t√≠picamente alcanzan scores de 60-80, haci√©ndolos accesibles para el p√∫blico general sin sacrificar precisi√≥n m√©dica.

### Notebooks

Explora los notebooks en `jupyter/` para an√°lisis m√°s detallados:

- `Clasificador.ipynb`: Pipeline completo de clasificaci√≥n PLS/NO_PLS
- `Qwen2_5_3B.ipynb`: Fine-tuning y evaluaci√≥n con Qwen 2.5 3B

## üìÅ Estructura del Proyecto

```
biores_maia/
‚îú‚îÄ‚îÄ streamlit/                      # Aplicaci√≥n web Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # Punto de entrada principal
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py            # M√≥dulo de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ validation.py               # M√≥dulo de validaci√≥n e inferencia
‚îÇ   ‚îú‚îÄ‚îÄ inference.py                # L√≥gica de inferencia con modelos
‚îÇ   ‚îú‚îÄ‚îÄ training.py                 # M√≥dulo de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ metrics_computer.py         # C√°lculo de m√©tricas textuales
‚îÇ   ‚îú‚îÄ‚îÄ metrics_visualizer.py       # Visualizaci√≥n de m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ clean_en_local.py           # Utilidades de limpieza de texto
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                    # Funciones auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt            # Dependencias espec√≠ficas
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        # Scripts de preprocesamiento y an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ clean_en.py                 # Pipeline de limpieza de texto
‚îÇ   ‚îú‚îÄ‚îÄ compute_metrics.py          # C√°lculo de m√©tricas de legibilidad
‚îÇ   ‚îú‚îÄ‚îÄ plot_distributions.py       # Visualizaci√≥n de distribuciones
‚îÇ   ‚îî‚îÄ‚îÄ data_raw/                   # Datos sin procesar (PLS/NO_PLS)
‚îÇ
‚îú‚îÄ‚îÄ inference/                      # Modelos y recursos para inferencia
‚îÇ   ‚îú‚îÄ‚îÄ qwen2.5-3b-pls/            # Adaptadores LoRA fine-tuneados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapter_config.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ adapter_model.safetensors
‚îÇ   ‚îú‚îÄ‚îÄ clasificador_medico_sencillo.pkl  # Clasificador BERT
‚îÇ   ‚îú‚îÄ‚îÄ td3_base_agent.zip         # Agente TD3 para modelo base
‚îÇ   ‚îú‚îÄ‚îÄ td3_lora_agent.zip         # Agente TD3 para modelo LoRA
‚îÇ   ‚îú‚îÄ‚îÄ examples.txt                # Ejemplos de texto m√©dico
‚îÇ   ‚îú‚îÄ‚îÄ test_inference.py           # Tests de inferencia
‚îÇ   ‚îî‚îÄ‚îÄ run_examples.sh             # Script para ejecutar ejemplos
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                      # Notebooks de an√°lisis y entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ Clasificador.ipynb          # Pipeline de clasificaci√≥n PLS/NO_PLS
‚îÇ   ‚îú‚îÄ‚îÄ Qwen2_5_3B.ipynb           # Fine-tuning con Qwen 2.5 3B
‚îÇ   ‚îî‚îÄ‚îÄ POC/                        # Pruebas de concepto
‚îÇ
‚îú‚îÄ‚îÄ config/                         # Archivos de configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                 # Configuraci√≥n principal del proyecto
‚îÇ
‚îú‚îÄ‚îÄ datos/                          # Datasets del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ PLS/                        # Textos en lenguaje simple
‚îÇ   ‚îî‚îÄ‚îÄ NO_PLS/                     # Textos m√©dicos complejos
‚îÇ
‚îú‚îÄ‚îÄ metrics/                        # Resultados de m√©tricas (generados)
‚îÇ   ‚îî‚îÄ‚îÄ *.parquet                   # M√©tricas computadas por chunk
‚îÇ
‚îú‚îÄ‚îÄ modelos/                        # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ Clasificador/               # Clasificador de textos m√©dicos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clasificador_medico_sencillo.pkl
‚îÇ   ‚îî‚îÄ‚îÄ qwen2.5-3b-pls/            # Adaptadores LoRA para Qwen 2.5 3B
‚îÇ       ‚îú‚îÄ‚îÄ adapter_config.json
‚îÇ       ‚îú‚îÄ‚îÄ adapter_model.safetensors
‚îÇ       ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ mockups/                        # Mockups y prototipos de UI
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing_configuration/
‚îÇ   ‚îú‚îÄ‚îÄ model_training_&_monitoring/
‚îÇ   ‚îî‚îÄ‚îÄ model_validation_&_testing/
‚îÇ
‚îú‚îÄ‚îÄ assets/                         # Recursos multimedia
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.png              # Captura m√≥dulo preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ inference.png               # Captura m√≥dulo inferencia
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml                  # Configuraci√≥n de proyecto y dependencias
‚îú‚îÄ‚îÄ uv.lock                         # Lock file de UV para reproducibilidad
‚îú‚îÄ‚îÄ Dockerfile                      # Imagen Docker para la aplicaci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml              # Orquestaci√≥n de servicios Docker
‚îú‚îÄ‚îÄ architecture.md                 # Documentaci√≥n de arquitectura
‚îî‚îÄ‚îÄ README.md                       # Este archivo
```



## üîß Configuraci√≥n

Edita `config/config.yaml` para ajustar parametros de scripts:

- Rutas de datos de entrada/salida
- Par√°metros de preprocesamiento
- Configuraci√≥n de m√©tricas y visualizaciones

## üõ†Ô∏è Desarrollo

### Instalaci√≥n de dependencias adicionales

```bash
# Con UV
uv pip install <paquete>

# Con pip
pip install <paquete>
```

### Hot-reload en Docker

El `docker-compose.yml` monta el directorio `streamlit/` como volumen, permitiendo hot-reload durante el desarrollo. Los cambios en el c√≥digo se reflejan autom√°ticamente sin necesidad de reconstruir la imagen.



